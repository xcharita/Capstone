{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import ndjson\n",
    "import os\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\PCCR\\\\SB\\\\Capstone'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set column width because of the max characters of 140 allowed in a tweet\n",
    "pd.options.display.max_colwidth=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the entire file into a python array\n",
    "with open('realdonaldtrump.ndjson', encoding='utf8') as f:\n",
    "    data = ndjson.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place file into a dataframe for further exploratoritive use\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Wed Apr 18 02:49:19 +0000 2018',\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'urls': [{'display_url': 'twitter.com/i/web/status/9…',\n",
       "    'expanded_url': 'https://twitter.com/i/web/status/986436485539770368',\n",
       "    'indices': [117, 140],\n",
       "    'url': 'https://t.co/pysLkufr7L'}],\n",
       "  'user_mentions': []},\n",
       " 'favorite_count': 61078,\n",
       " 'favorited': False,\n",
       " 'geo': None,\n",
       " 'id': 986436485539770368,\n",
       " 'id_str': '986436485539770368',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'is_quote_status': False,\n",
       " 'lang': 'ja',\n",
       " 'place': None,\n",
       " 'possibly_sensitive': False,\n",
       " 'retweet_count': 18259,\n",
       " 'retweeted': False,\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'text': 'フロリダに到着し、早速トランプ大統領との首脳会談に臨みました。今日は、大半を北朝鮮問題に費やし、非常に重要な点で認識を一致させることができました。\\n「日本のために最善となるようベストを尽くす」\\nトランプ大統領は、来る米朝首脳会談で… https://t.co/pysLkufr7L',\n",
       " 'truncated': True,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Thu Jan 19 06:02:29 +0000 2012',\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'description': '衆議院議員安倍晋三（あべしんぞう）の公式twitterです。 \\nPrime Minister of Japan. Leader of Liberal Democratic Party.',\n",
       "  'entities': {'description': {'urls': []},\n",
       "   'url': {'urls': [{'display_url': 's-abe.or.jp',\n",
       "      'expanded_url': 'http://www.s-abe.or.jp/',\n",
       "      'indices': [0, 22],\n",
       "      'url': 'http://t.co/hTEyS9iLvU'}]}},\n",
       "  'favourites_count': 10,\n",
       "  'follow_request_sent': False,\n",
       "  'followers_count': 1441945,\n",
       "  'following': False,\n",
       "  'friends_count': 18,\n",
       "  'geo_enabled': True,\n",
       "  'has_extended_profile': False,\n",
       "  'id': 468122115,\n",
       "  'id_str': '468122115',\n",
       "  'is_translation_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'lang': None,\n",
       "  'listed_count': 11482,\n",
       "  'location': '',\n",
       "  'name': '安倍晋三',\n",
       "  'notifications': False,\n",
       "  'profile_background_color': '000000',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme16/bg.gif',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme16/bg.gif',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/468122115/1507347517',\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1765776666/s-abetwitter1_normal.png',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1765776666/s-abetwitter1_normal.png',\n",
       "  'profile_link_color': '3B94D9',\n",
       "  'profile_sidebar_border_color': '000000',\n",
       "  'profile_sidebar_fill_color': '000000',\n",
       "  'profile_text_color': '000000',\n",
       "  'profile_use_background_image': False,\n",
       "  'protected': False,\n",
       "  'screen_name': 'AbeShinzo',\n",
       "  'statuses_count': 1695,\n",
       "  'time_zone': None,\n",
       "  'translator_type': 'none',\n",
       "  'url': 'http://t.co/hTEyS9iLvU',\n",
       "  'utc_offset': None,\n",
       "  'verified': True}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[34757].retweeted_status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>scopes</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "      <th>withheld_copyright</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "      <th>withheld_scope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [contributors, coordinates, created_at, entities, extended_entities, favorite_count, favorited, geo, id, id_str, in_reply_to_screen_name, in_reply_to_status_id, in_reply_to_status_id_str, in_reply_to_user_id, in_reply_to_user_id_str, is_quote_status, lang, place, possibly_sensitive, quoted_status, quoted_status_id, quoted_status_id_str, retrieved_utc, retweet_count, retweeted, retweeted_status, scopes, source, text, truncated, user, withheld_copyright, withheld_in_countries, withheld_scope]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating bool series True for NaN values  \n",
    "bool_series = pd.isnull(df['retweet_count'])  \n",
    "    \n",
    "# filtering data\n",
    "df[bool_series]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n"
     ]
    }
   ],
   "source": [
    "print(np.sum([df['lang'] != 'en']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_drop = []\n",
    "for i in range(len(df)):\n",
    "    if (df.lang[i] != 'en'):\n",
    "        list_for_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n"
     ]
    }
   ],
   "source": [
    "print(len(list_for_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(list_for_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Clean the data by:\n",
    "\n",
    "1. Removing all irrelevant characters such as any non alphanumeric characters\n",
    "2. Tokenize the text by separating it into individual words\n",
    "3. Remove words that are not relevant, such as “@” twitter mentions or urls\n",
    "4. Convert all characters to lowercase, in order to treat words such as “hello”, “Hello”, and “HELLO” the same\n",
    "5. Considering combining misspelled or alternately spelled words to a single representation (e.g. “cool”/”kewl”/”cooool”)\n",
    "6. Considering lemmatization (reduce words such as “am”, “are”, and “is” to a common form such as “be”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame(df_new, columns = ('retweet_count', 'text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          501\n",
       "1           33\n",
       "2           13\n",
       "3           12\n",
       "4         1422\n",
       "5           29\n",
       "6           15\n",
       "7           15\n",
       "8           14\n",
       "9           21\n",
       "10          29\n",
       "11          67\n",
       "12          17\n",
       "13          26\n",
       "14          10\n",
       "15          28\n",
       "16          13\n",
       "17          54\n",
       "18          27\n",
       "19           4\n",
       "20          57\n",
       "21          14\n",
       "22          13\n",
       "23          11\n",
       "24          17\n",
       "25          36\n",
       "26          20\n",
       "27          69\n",
       "28          15\n",
       "29          26\n",
       "         ...  \n",
       "40211    19254\n",
       "40212    16651\n",
       "40213    17246\n",
       "40214    11651\n",
       "40215     9445\n",
       "40216    20162\n",
       "40217    13278\n",
       "40218    21255\n",
       "40219    22745\n",
       "40220    10608\n",
       "40221    13420\n",
       "40222    14332\n",
       "40223    11570\n",
       "40224     7667\n",
       "40225     9529\n",
       "40226     8219\n",
       "40227     9527\n",
       "40228     7598\n",
       "40229    20914\n",
       "40230     7971\n",
       "40231     7307\n",
       "40232     8154\n",
       "40233     7363\n",
       "40234     7239\n",
       "40235    13489\n",
       "40236     6331\n",
       "40237     7694\n",
       "40238     2540\n",
       "40239     4533\n",
       "40240     5236\n",
       "Name: retweet_count, Length: 39570, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.retweet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_of_tweets = df_clean['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a first round of text cleaning techniques\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(txt):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub('\\[.*?@\\#]', ' ', txt)\n",
    "    txt = re.sub('[%s]' % re.escape(string.punctuation), '', txt)\n",
    "    txt = re.sub('\\w*\\d\\w*', ' ', txt)\n",
    "    txt = re.sub('\\n', ' ', txt)\n",
    "    return txt\n",
    "\n",
    "round1 = lambda x: clean_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt abeshinzo フロリダに到着し、早速トランプ大統領との首脳会談に臨みました。今日は、大半を北朝鮮問題に費やし、非常に重要な点で認識を一致させることができました。 「日本のために最善となるようベストを尽くす」 トランプ大統領は、来る米朝首脳会談で拉致問題を取り上げ…'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The updated text\n",
    "data_clean_first = pd.DataFrame(text_of_tweets.apply(round1))\n",
    "data_clean_first.text[34757]\n",
    "#data_clean_first.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', ' ', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40030        i am in south korea now president moon and i have  toasted  our new trade deal a far better one for us than that   \n",
       "40031        the highly respected farm journal has just announced my approval rating with our great farmers at   and that des   \n",
       "40032         the leaders of virtually every country that i met at the   congratulated me on our great economy many countries   \n",
       "40033    rt thebluehousekr realdonaldtrump   hellopolicy mofakr secpompeo 오울렛 초소에서 브리핑을 받고 북측을 바라보며 대화하는 한미 정상의 모습 오울렛 초소는 한국전쟁 \n",
       "40034       leaving south korea after a wonderful meeting with chairman kim jong un stood on the soil of north korea an impor   \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The updated text\n",
    "data_clean_second = pd.DataFrame(data_clean_first.text.apply(round2))\n",
    "data_clean_second.text[40030:40035]\n",
    "#data_clean_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a third round of cleaning\n",
    "def clean_text_round3(text):\n",
    "    '''Get rid of the http sites.'''\n",
    "    text = re.sub('http\\\\w*', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "round3 = lambda x: clean_text_round3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt abeshinzo フロリダに到着し、早速トランプ大統領との首脳会談に臨みました。今日は、大半を北朝鮮問題に費やし、非常に重要な点で認識を一致させることができました。 「日本のために最善となるようベストを尽くす」 トランプ大統領は、来る米朝首脳会談で拉致問題を取り上げ '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The updated text\n",
    "data_clean_third = pd.DataFrame(data_clean_second.text.apply(round3))\n",
    "data_clean_third.text[34757]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_dtm = pd.DataFrame(cv.fit_transform(data_clean_third.text).toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_drop = cv.get_feature_names()[-72:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt abeshinzo フロリダに到着し、早速トランプ大統領との首脳会談に臨みました。今日は、大半を北朝鮮問題に費やし、非常に重要な点で認識を一致させることができました。 「日本のために最善となるようベストを尽くす」 トランプ大統領は、来る米朝首脳会談で拉致問題を取り上げ '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean_third.text[34757]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33681  ありがとうございます\n",
      "33697  そして\n",
      "33697  アジア歴訪の大成功をお祈りしています\n",
      "33697  トランプ大統領\n",
      "33697  トランプ大統領による\n",
      "33697  ドナルド\n",
      "33697  初の\n",
      "33697  日米同盟の揺るぎない絆を世界に示すことができました\n",
      "33697  本当にありがとう\n",
      "33697  歴史的な日本訪問は\n",
      "33697  間違いなく\n",
      "34757  トランプ大統領\n",
      "34757  トランプ大統領は\n",
      "34757  フロリダに到着し\n",
      "34757  今日は\n",
      "34757  大半を北朝鮮問題に費やし\n",
      "34757  日本のために最善となるようベストを尽くす\n",
      "34757  早速トランプ大統領との首脳会談に臨みました\n",
      "34757  来る米朝首脳会談で拉致問題を取り上げ\n",
      "34757  非常に重要な点で認識を一致させることができました\n",
      "37239  この機会を活かし\n",
      "37239  という共通の目標に向かって\n",
      "37239  トランプ大統領\n",
      "37239  モディ首相と\n",
      "37239  初めてとなる日米印三か国による首脳会談を行いました\n",
      "37239  緊密に連携していくことで一致しました\n",
      "37239  自由で開かれたインド太平洋\n",
      "37956  رژیم\n",
      "37956  سال\n",
      "37956  سرکوب\n",
      "37956  شده\n",
      "37956  فساد\n",
      "37956  فقط\n",
      "37956  مدتهاست\n",
      "37956  مردم\n",
      "37956  موجب\n",
      "37956  چهلسالشکست\n",
      "37956  که\n",
      "38903  そして\n",
      "38903  そして本日のゴルフと\n",
      "38903  北朝鮮問題への対応\n",
      "38903  昨日の首脳会談\n",
      "38903  更には世界情勢に至るまで\n",
      "38903  本日\n",
      "38903  様々な課題についてじっくりと話をすることができました\n",
      "38903  経済\n",
      "39505  トランプ大統領\n",
      "39505  日本へようこそ\n",
      "39507  トランプ大統領\n",
      "39507  令和初の国賓としてお迎えしたトランプ大統領と千葉でゴルフです\n",
      "39507  初の\n",
      "39507  新しい令和の時代も日米同盟をさらに揺るぎないものとしていきたいと考えています\n",
      "39515  トランプ大統領\n",
      "39515  トランプ大統領は\n",
      "39515  トランプ大統領は安倍首相と共に皇居での歓迎式典に出席しました\n",
      "39517  トランプ大統領\n",
      "39517  トランプ大統領とメラニア夫人は\n",
      "39517  天皇\n",
      "39517  皇后両陛下との会見に臨みました\n",
      "39535  かが\n",
      "39535  を訪問しました\n",
      "39535  トランプ大統領\n",
      "39535  トランプ大統領と共に\n",
      "39535  史上初めてのことです\n",
      "39535  日米両国の首脳が揃って\n",
      "39535  本日\n",
      "39535  海上自衛隊の護衛艦\n",
      "39535  米軍を激励するのは\n",
      "39535  総理メッセージの続きは\n",
      "39535  自衛隊\n",
      "40033  대화하는\n",
      "40033  모습\n",
      "40033  바라보며\n",
      "40033  받고\n",
      "40033  북측을\n",
      "40033  브리핑을\n",
      "40033  오울렛\n",
      "40033  정상의\n",
      "40033  초소는\n",
      "40033  초소에서\n",
      "40033  한국전쟁\n",
      "40033  한미\n"
     ]
    }
   ],
   "source": [
    "number_for_drop = []\n",
    "for i in range(len(data_clean_third.text)-1):\n",
    "    for sign in list_for_drop:\n",
    "        if re.search(sign, data_clean_third.text[i]):\n",
    "            print(i, '', sign)\n",
    "            number_for_drop.append(i)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(number_for_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
